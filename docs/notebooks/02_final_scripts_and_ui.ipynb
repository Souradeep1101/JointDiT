{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 02 — Final scripts + Gradio UI\n",
    "\n",
    "**Goal:** collect the finished train/infer scripts into a repeatable workflow, add a lightweight UI, and document VRAM profiles + troubleshooting.\n",
    "\n",
    "**Artifacts in repo:**\n",
    "- Final scripts: `scripts/finals/train.sh`, `scripts/finals/infer.sh`\n",
    "- Inference UI: `scripts/ui/app.py`  (exposes Day-6 sampler via Gradio)\n",
    "- Make targets: `make final-train-a`, `make final-train-b`, `make final-infer`, `make ui`\n",
    "\n",
    "This notebook summarizes how to run **training (Stage-A/B)**, **CLI inference**, and **UI inference**, plus fixes for common UI dependency hiccups (e.g., “No API found” / schema crash).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Repo map (relevant to Day 02)\n",
    "\n",
    "```\n",
    "scripts/\n",
    "  finals/\n",
    "    train.sh        # Stage A/B driver (reads VRAM envs)\n",
    "    infer.sh        # CLI inference (Day-6 sampler)\n",
    "  ui/\n",
    "    app.py          # Gradio app (mp4+wav)\n",
    "configs/\n",
    "  day05_train.yaml  # Stage-A config\n",
    "  day07_trainB.yaml # Stage-B config\n",
    "  day06_infer.yaml  # Day-6 sampler config used by CLI/UI\n",
    "  ui_infer.yaml     # UI defaults (paths)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) VRAM profiles (export **before** running)\n",
    "\n",
    "These control time-token truncation and attention chunking/downsampling. They’re honored by both Make targets and the shell scripts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "## Choose ONE profile and run in your shell session\n",
    "\n",
    "echo \"# Max-Quality (>=80GB)\"\n",
    "cat <<'EOF'\n",
    "export JOINTDIT_MAX_T=12\n",
    "export JOINTDIT_Q_CHUNK_V=128\n",
    "export JOINTDIT_Q_CHUNK_A=0\n",
    "export JOINTDIT_KV_DOWNSAMPLE=4\n",
    "export PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:128\"\n",
    "EOF\n",
    "\n",
    "echo\n",
    "echo \"# Balanced (~48GB)\"\n",
    "cat <<'EOF'\n",
    "export JOINTDIT_MAX_T=12\n",
    "export JOINTDIT_Q_CHUNK_V=128\n",
    "export JOINTDIT_Q_CHUNK_A=0\n",
    "export JOINTDIT_KV_DOWNSAMPLE=4\n",
    "export PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:128\"\n",
    "EOF\n",
    "\n",
    "echo\n",
    "echo \"# Conservative (<=24GB)\"\n",
    "cat <<'EOF'\n",
    "export JOINTDIT_MAX_T=6\n",
    "export JOINTDIT_Q_CHUNK_V=64\n",
    "export JOINTDIT_Q_CHUNK_A=0\n",
    "export JOINTDIT_KV_DOWNSAMPLE=8\n",
    "export PYTORCH_CUDA_ALLOC_CONF=\"max_split_size_mb:128\"\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Training — Stage-A / Stage-B\n",
    "\n",
    "Both paths accept `--max-steps`, `--ckpt-suffix`, and `--log-suffix`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Stage A (Make or direct)\n",
    "make final-train-a\n",
    "# Or:\n",
    "PYTHONPATH=. scripts/finals/train.sh \\\n",
    "  --stage A --cfg configs/day05_train.yaml \\\n",
    "  --max-steps 25 --ckpt-suffix finalA --log-suffix finalA\n",
    "\n",
    "# Stage B (Make or direct)\n",
    "make final-train-b\n",
    "# Or:\n",
    "PYTHONPATH=. scripts/finals/train.sh \\\n",
    "  --stage B --cfg configs/day07_trainB.yaml \\\n",
    "  --max-steps 1000 --ckpt-suffix finalB --log-suffix finalB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Inference — CLI (Day-6 sampler)\n",
    "\n",
    "Outputs MP4 and WAV using the VAEs + sampler settings from Day-6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "make final-infer\n",
    "# Or:\n",
    "PYTHONPATH=. scripts/finals/infer.sh \\\n",
    "  --cfg configs/day06_infer.yaml \\\n",
    "  --ckpt checkpoints/day07_stage_b_finalB/ckpt_step_001000.pt \\\n",
    "  --steps 30 --seed 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Inference — Gradio UI\n",
    "\n",
    "Start the app and open the URL (default: http://127.0.0.1:7860). Fill paths, pick VRAM profile, set steps/CFG, then **Run**.\n",
    "\n",
    "**Known dependency gotchas** and fixes are below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "make ui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1) UI Troubleshooting (dependency pins)\n",
    "\n",
    "**If you see:** “No API found” or a JSON-schema crash from `gradio_client.utils` → you’re hitting a FastAPI/Starlette/Gradio schema mismatch. Two proven pin sets:\n",
    "\n",
    "**Option A (stable with current repo):**\n",
    "```bash\n",
    "pip install -U \"altair<6\" \"numpy==1.26.4\"\n",
    "pip install --no-deps --force-reinstall \"gradio==4.19.2\" \"gradio_client==0.10.1\"\n",
    "pip install \"fastapi<0.112\" \"starlette<0.37\" \"uvicorn<0.30\"\n",
    "```\n",
    "\n",
    "**Option B (newer gradio):**\n",
    "```bash\n",
    "pip install -U \"gradio==4.44.0\" \"gradio_client==1.4.2\"\n",
    "pip check\n",
    "```\n",
    "\n",
    "The app also includes a small **schema safety patch** that bypasses the problematic API schema route.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Audio notes\n",
    "\n",
    "- Ensure `torchaudio` is installed for Griffin-Lim inversion:\n",
    "  ```bash\n",
    "  pip install torchaudio\n",
    "  ```\n",
    "- Inversion uses meta values: `n_mels`, `hop_length`, `win_length`, `fmin`, `fmax`. Silent WAVs usually mean a mismatch with cached meta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Outputs & checkpoints\n",
    "\n",
    "- UI writes to `outputs/ui/`\n",
    "- CLI Day-6 writes to `outputs/day06/`\n",
    "- Checkpoints: `checkpoints/day05_stage_a_*` and `checkpoints/day07_stage_b_*`\n",
    "\n",
    "**Tip:** the Makefile sets `FORCE_KEEP_USER_ENVS=1` so your exported VRAM envs override defaults.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
